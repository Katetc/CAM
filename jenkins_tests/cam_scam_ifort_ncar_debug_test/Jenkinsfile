pipeline {
  agent any
  stages {
    stage('Check out externals') {
       steps {
          sh 'python manage_externals/checkout_externals -e Externals.cfg'
       }
    }
    stage('Copy Config Files') {
      steps {
         sh """#!/bin/bash
               cp -rf cime_config_cesm_machines_files/config_machines.xml cime/config/cesm/machines/config_machines.xml
               cp -rf cime_config_cesm_machines_files/config_compilers.xml cime/config/cesm/machines/config_compilers.xml
               # This sed command modifies the test script to use the intel machine configuration, and turn on debugging for the test. 
               sed -i '14s|nelson|nelson_intel|' run_scripts/run_scam.bash
               sed -i '89s|#||' run_scripts/run_scam.bash
               sed -i '89s|FALSE|TRUE|' run_scripts/run_scam.bash"""
       }
    }
    stage('Remove Old Output') {
       steps {
          // This removes the output stored outside of the jenkins workspace so the test can run
          sh 'rm -rf /home/jenkins/cam_output/scratch/test_scam_atex /home/jenkins/cam_output/scratch/test_scam_arm97'
          script {
            // For the branch test, the workspace is not cleaned after every run, this step ensures it is clean for the current run
            if ("${env.JOB_NAME}" == "branch_cam_test")
              sh "rm -rf ${env.WORKSPACE}/cime/scripts/test_scam_atex ${env.WORKSPACE}/cime/scripts/test_scam_arm97"
          }
       }
    }
    stage('Run atex') {
       steps {
          // The source step is done to bring in all the needed intel path variables to run the rest of the commands
          sh '''source /opt/intel/oneapi/setvars.sh --force
                run_scripts/run_scam.bash atex'''
       }
    }
    stage('Run arm97 with SILHS') {
       steps {
          // The source step is done to bring in all the needed intel path variables to run the rest of the commands
          sh '''source /opt/intel/oneapi/setvars.sh --force
                # ulimit line is here so that we can override the default stack limit so that the program can write larger files properly
                ulimit -s 8388608
                run_scripts/run_scam.bash -s arm97'''
       }
    }
  }
  post {
    always {
      // Certain logical functions like IF statements or TRY-CATCH blocks can only operate while in a script{} block
      script {
        // This checks if the current test matches the name of the official test
        // We do this to prevent the branch tests and the clubb copy tests from removing its output
        // so they can be referenced later for debugging
        if ( "${env.JOB_NAME}" == "cam_scam_ifort_ncar_debug_test" )
          cleanWs(cleanWhenSuccess: true, cleanWhenFailure: true)
        
        sh 'chmod -R 755 /home/jenkins/cam_output/'

        // The try catch blocks here are to prevent the script from ending the run if the logs are not present to be displayed
        // They catch the exception and print a statement then move on to the next step
        try {
           // These logs are made during a normal run of this test and are unzipped
           // and displayed to the console so they are easily accessible for debugging
           // On a failed run it may not have all these logs
           sh '''gzip -d /home/jenkins/cam_output/scratch/test_scam_atex/bld/atm.bldlog.*.gz
                 cat /home/jenkins/cam_output/scratch/test_scam_atex/bld/atm.bldlog.*'''
           sh '''gzip -d /home/jenkins/cam_output/scratch/test_scam_atex/bld/cesm.bldlog.*.gz
                 cat /home/jenkins/cam_output/scratch/test_scam_atex/bld/cesm.bldlog.*'''
           sh '''gzip -d /home/jenkins/cam_output/scratch/test_scam_atex/run/atm.log.*.gz
                 cat /home/jenkins/cam_output/scratch/test_scam_atex/run/atm.log.*'''
           sh '''gzip -d /home/jenkins/cam_output/scratch/test_scam_atex/run/cesm.log.*.gz
                 cat /home/jenkins/cam_output/scratch/test_scam_atex/run/cesm.log.*'''
        } catch (Exception e) {
           // This message prints to the Jenkins test console when an error occurs in the above block, usually a log is missing
           echo 'Not all logs were made for atex.'  	
        }

        try {
           sh '''gzip -d /home/jenkins/cam_output/scratch/test_scam_arm97/bld/atm.bldlog.*.gz
                 cat /home/jenkins/cam_output/scratch/test_scam_arm97/bld/atm.bldlog.*'''
           sh '''gzip -d /home/jenkins/cam_output/scratch/test_scam_arm97/bld/cesm.bldlog.*.gz
                 cat /home/jenkins/cam_output/scratch/test_scam_arm97/bld/cesm.bldlog.*'''
           sh '''gzip -d /home/jenkins/cam_output/scratch/test_scam_arm97/run/atm.log.*.gz
                 cat /home/jenkins/cam_output/scratch/test_scam_arm97/run/atm.log.*'''
           sh '''gzip -d /home/jenkins/cam_output/scratch/test_scam_arm97/run/cesm.log.*.gz
                 cat /home/jenkins/cam_output/scratch/test_scam_arm97/run/cesm.log.*'''
        } catch (Exception e) {
           echo 'Not all logs were made for arm97.'  	
        }
      }
    }
    failure {
      script {
        if ( "${env.JOB_NAME}" ==	"cam_scam_ifort_ncar_debug_test" )
           // This command handles the email on failure feature of the jenkins test. This line is the same on every jenkins test.
	   emailext(to: 'messnermet@uwm.edu', subject: "${env.JOB_NAME} build ${env.BUILD_NUMBER} has Failed", attachLog: true, body: "${env.JOB_NAME} build ${env.BUILD_NUMBER} has failed. See the attached build log and the build results (${env.BUILD_URL}) for help troubleshooting.")
      }
    }
  }
}
